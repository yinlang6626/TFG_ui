import os
import time
import json
import subprocess
import torch
import threading
from datetime import datetime

from nltk.lm import Vocabulary
from openvoice.api import BaseSpeakerTTS, ToneColorConverter
from openvoice import se_extractor
from .path_manager import PathManager


class ModelDownloader:
    """æ¨¡å‹ä¸‹è½½å™¨ï¼Œå¤„ç†æ¨¡å‹æ–‡ä»¶çš„ä¸‹è½½å’Œè§£å‹"""

    @staticmethod
    def download_with_progress(url, output_path):
        """æ–‡ä»¶ä¸‹è½½è¿›åº¦æ˜¾ç¤º"""
        import requests

        try:
            response = requests.get(url, stream=True)
            response.raise_for_status()

            total_size = int(response.headers.get('content-length', 0))
            downloaded = 0

            with open(output_path, 'wb') as f:
                for chunk in response.iter_content(chunk_size=8192):
                    f.write(chunk)
                    downloaded += len(chunk)

                    if total_size > 0:
                        progress = (downloaded / total_size) * 100
                        print(f"\r[OpenVoice] ä¸‹è½½è¿›åº¦: {progress:.1f}%", end='', flush=True)

            print()  # æ¢è¡Œ

        except Exception as e:
            print(f"[OpenVoice] ä¸‹è½½å¤±è´¥: {e}")
            raise

    @staticmethod
    def extract_zip_file(zip_path, extract_dir):
        """è§£å‹zipæ–‡ä»¶"""
        import zipfile

        try:
            with zipfile.ZipFile(zip_path, 'r') as zip_ref:
                zip_ref.extractall(extract_dir)

            print(f"[OpenVoice] è§£å‹å®Œæˆ: {zip_path} -> {extract_dir}")

        except Exception as e:
            print(f"[OpenVoice] è§£å‹å¤±è´¥: {e}")
            raise


class AudioProcessor:
    """éŸ³é¢‘å¤„ç†å™¨ï¼Œå¤„ç†éŸ³é¢‘ç›¸å…³çš„æ“ä½œ"""

    def __init__(self):
        self.path_manager = PathManager()

    def extract_audio_from_video(self, video_path):
        """ä»è§†é¢‘ä¸­æå–éŸ³é¢‘"""
        try:
            # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨ - ä½¿ç”¨PathManager
            audio_dir = self.path_manager.get_ref_voice_path()
            self.path_manager.ensure_directory(audio_dir)

            # ç”ŸæˆéŸ³é¢‘æ–‡ä»¶å - ä½¿ç”¨PathManager
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            audio_output = self.path_manager.get_extracted_voice_path(timestamp)

            # ä½¿ç”¨ffmpegæå–éŸ³é¢‘
            cmd = [
                "ffmpeg", "-i", video_path,
                "-vn",  # ç¦ç”¨è§†é¢‘
                "-acodec", "pcm_s24le",  # éŸ³é¢‘ç¼–ç 
                "-ar", "22050",  # é‡‡æ ·ç‡
                "-af", "highpass=80,lowpass=8000,dynaudnorm=p=0.95:s=5",  # å•å£°é“
                "-y",  # è¦†ç›–è¾“å‡ºæ–‡ä»¶
                audio_output
            ]

            print(f"[backend.model_trainer] æå–éŸ³é¢‘å‘½ä»¤: {' '.join(cmd)}")

            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                timeout=60  # 1åˆ†é’Ÿè¶…æ—¶
            )

            if result.returncode == 0:
                print(f"[backend.model_trainer] éŸ³é¢‘æå–æˆåŠŸ: {audio_output}")
                return audio_output
            else:
                print(f"[backend.model_trainer] éŸ³é¢‘æå–å¤±è´¥: {result.stderr}")
                return None

        except subprocess.TimeoutExpired:
            print("[backend.model_trainer] éŸ³é¢‘æå–è¶…æ—¶")
            return None
        except Exception as e:
            print(f"[backend.model_trainer] éŸ³é¢‘æå–å¼‚å¸¸: {e}")
            return None


class SpeakerFeatureManager:
    """è¯´è¯äººç‰¹å¾ç®¡ç†å™¨ - ä¸“é—¨å¤„ç†è¯´è¯äººç‰¹å¾çš„åŠ è½½ã€ä¿å­˜å’Œç®¡ç†"""

    def __init__(self, path_manager):
        self.path_manager = path_manager
        self.speaker_features = {}
        self._load_all_features()

    def _load_all_features(self):
        """åŠ è½½æ‰€æœ‰å·²ä¿å­˜çš„è¯´è¯äººç‰¹å¾"""
        features_file = self.path_manager.get_speaker_features_path()
        if os.path.exists(features_file):
            try:
                with open(features_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)

                # åŠ è½½ç‰¹å¾å¼ é‡
                for speaker_id, info in data.items():
                    feature_path = info['feature_path']
                    if os.path.exists(feature_path):
                        self.speaker_features[speaker_id] = {
                            'se': torch.load(feature_path, map_location='cpu'),
                            'reference_audio': info['reference_audio'],
                            'created_time': info['created_time']
                        }

                print(f"[SpeakerFeatureManager] å·²åŠ è½½ {len(self.speaker_features)} ä¸ªè¯´è¯äººç‰¹å¾")
            except Exception as e:
                print(f"[SpeakerFeatureManager] åŠ è½½è¯´è¯äººç‰¹å¾å¤±è´¥: {e}")

    def save_feature(self, speaker_id, reference_audio, se_tensor):
        """ä¿å­˜è¯´è¯äººç‰¹å¾"""
        try:
            # ä¿å­˜ç‰¹å¾å¼ é‡ - ä½¿ç”¨PathManagerçš„ä¸“é—¨æ–¹æ³•
            feature_path = self.path_manager.get_speaker_feature_tensor_path(speaker_id)
            torch.save(se_tensor, feature_path)

            # ä¿å­˜å…ƒæ•°æ®
            metadata = {
                'feature_path': feature_path,
                'reference_audio': reference_audio,
                'created_time': time.strftime("%Y-%m-%d %H:%M:%S")
            }

            # æ›´æ–°ç‰¹å¾æ–‡ä»¶
            features_file = self.path_manager.get_speaker_features_path()
            all_features = {}
            if os.path.exists(features_file):
                with open(features_file, 'r', encoding='utf-8') as f:
                    all_features = json.load(f)

            all_features[speaker_id] = metadata

            with open(features_file, 'w', encoding='utf-8') as f:
                json.dump(all_features, f, indent=2, ensure_ascii=False)

            # æ›´æ–°å†…å­˜ä¸­çš„ç‰¹å¾
            self.speaker_features[speaker_id] = {
                'se': se_tensor,
                'reference_audio': reference_audio,
                'created_time': metadata['created_time']
            }

            print(f"[SpeakerFeatureManager] è¯´è¯äººç‰¹å¾å·²ä¿å­˜: {speaker_id}")

        except Exception as e:
            print(f"[SpeakerFeatureManager] ä¿å­˜è¯´è¯äººç‰¹å¾å¤±è´¥: {e}")

    def get_feature(self, speaker_id):
        """è·å–æŒ‡å®šè¯´è¯äººçš„ç‰¹å¾"""
        return self.speaker_features.get(speaker_id)

    def list_speakers(self):
        """åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„è¯´è¯äºº"""
        return list(self.speaker_features.keys())

    def extract_feature(self, speaker_id, reference_audio, tone_converter):
        """æå–è¯´è¯äººç‰¹å¾"""
        try:
            if not tone_converter:
                print(f"[SpeakerFeatureManager] è½¬æ¢å™¨æœªåˆå§‹åŒ–")
                return False

            print(f"[SpeakerFeatureManager] å¼€å§‹æå–è¯´è¯äººç‰¹å¾: {speaker_id}")

            # æå–è¯´è¯äººç‰¹å¾ - ä½¿ç”¨PathManagerè·å–processedç›®å½•
            processed_dir = self.path_manager.get_processed_path()
            target_se_result = se_extractor.get_se(
                reference_audio,
                vc_model=tone_converter,
                target_dir=processed_dir,
                vad=True
            )

            # get_seè¿”å›å…ƒç»„(se_tensor, audio_name) åªéœ€è¦å¼ é‡éƒ¨åˆ†
            if isinstance(target_se_result, tuple):
                target_se = target_se_result[0]
            else:
                target_se = target_se_result

            # ä¿å­˜ç‰¹å¾
            self.save_feature(speaker_id, reference_audio, target_se)

            print(f"[SpeakerFeatureManager] è¯´è¯äººç‰¹å¾æå–å®Œæˆ: {speaker_id}")
            return True

        except Exception as e:
            print(f"[SpeakerFeatureManager] è¯´è¯äººç‰¹å¾æå–å¤±è´¥: {e}")
            return False


class ModelManager:
    """æ¨¡å‹ç®¡ç†å™¨ - ä¸“é—¨å¤„ç†æ¨¡å‹çš„åˆå§‹åŒ–ã€ä¸‹è½½å’Œç®¡ç†"""

    def __init__(self, path_manager):
        self.path_manager = path_manager
        self.device = DeviceUtils._get_optimal_device()
        self.tone_converter = None

    def initialize(self):
        """åˆå§‹åŒ–æ¨¡å‹"""
        try:
            # ç¡®ä¿ç›®å½•å­˜åœ¨
            self._ensure_directories()

            # æ£€æŸ¥æ¨¡å‹æ˜¯å¦å­˜åœ¨
            if not self._check_models_exist():
                print("[ModelManager] æ£€æµ‹åˆ°æ¨¡å‹æ–‡ä»¶ç¼ºå¤±ï¼Œå¼€å§‹è‡ªåŠ¨ä¸‹è½½...")
                self._download_models()

            # é…ç½®æ¨¡å‹è·¯å¾„ - ä½¿ç”¨PathManager
            config_path = self.path_manager.get_openvoice_v2_path("converter/config.json")
            base_ckpt = self.path_manager.get_openvoice_v2_path("converter/checkpoint.pth")

            # åŠ è½½éŸ³è‰²è½¬æ¢å™¨ï¼ˆç¦ç”¨æ°´å°ä»¥é¿å…ä¸‹è½½æ¨¡å‹ï¼‰
            self.tone_converter = ToneColorConverter(config_path, device=self.device)
            self.tone_converter.load_ckpt(base_ckpt)

            print(f"[ModelManager] V2æ¨¡å‹åŠ è½½å®Œæˆï¼Œä½¿ç”¨è®¾å¤‡: {self.device}")
            return True

        except Exception as e:
            print(f"[ModelManager] æ¨¡å‹åˆå§‹åŒ–å¤±è´¥: {e}")
            return False



    def _ensure_directories(self):
        """ç¡®ä¿å¿…è¦ç›®å½•å­˜åœ¨"""
        dirs = [
            self.path_manager.get_openvoice_v2_path(),
            self.path_manager.get_root_begin_path("OpenVoice/checkpoints/base_speakers"),
            self.path_manager.get_openvoice_model_path(),
            self.path_manager.get_ref_voice_path(),                    # å‚è€ƒéŸ³é¢‘ç›®å½•
            self.path_manager.get_res_voice_path(),                    # ç»“æœéŸ³é¢‘ç›®å½•
            self.path_manager.get_processed_path()
        ]
        for dir_path in dirs:
            self.path_manager.ensure_directory(dir_path)
            print(f"[ModelManager] ç¡®ä¿ç›®å½•å­˜åœ¨: {dir_path}")

    def _check_models_exist(self):
        """æ£€æŸ¥æ¨¡å‹æ–‡ä»¶æ˜¯å¦å­˜åœ¨"""
        required_files = [
            self.path_manager.get_openvoice_v2_path("converter/config.json"),
            self.path_manager.get_openvoice_v2_path("converter/checkpoint.pth")
        ]

        missing = [f for f in required_files if not os.path.exists(f)]
        if missing:
            print(f"[ModelManager] ç¼ºå¤±æ¨¡å‹æ–‡ä»¶: {missing}")
            return False
        return True

    def _download_models(self):
        """ä¸‹è½½OpenVoice V2é¢„è®­ç»ƒæ¨¡å‹"""
        print("[ModelManager] ä¸‹è½½OpenVoice V2é¢„è®­ç»ƒæ¨¡å‹...")

        try:
            # V2æ¨¡å‹ä¸‹è½½åœ°å€
            zip_url = "https://myshell-public-repo-host.s3.amazonaws.com/openvoice/checkpoints_v2_0417.zip"

            # ä½¿ç”¨PathManagerè·å–è·¯å¾„
            project_root = self.path_manager.project_root
            zip_path = os.path.join(project_root, "OpenVoice/checkpoints_v2_0417.zip")
            extract_dir = os.path.join(project_root, "OpenVoice/")

            print(f"[ModelManager] ä¸‹è½½V2æ£€æŸ¥ç‚¹å‹ç¼©åŒ…...")
            ModelDownloader.download_with_progress(zip_url, zip_path)

            # è§£å‹å‹ç¼©åŒ…
            print(f"[ModelManager] è§£å‹æ£€æŸ¥ç‚¹æ–‡ä»¶...")
            ModelDownloader.extract_zip_file(zip_path, extract_dir)

            # æ¸…ç†å‹ç¼©åŒ…æ–‡ä»¶
            if os.path.exists(zip_path):
                os.remove(zip_path)
                print(f"[ModelManager] æ¸…ç†å‹ç¼©åŒ…æ–‡ä»¶: {zip_path}")

            print("[ModelManager] V2æ¨¡å‹ä¸‹è½½å’Œè§£å‹å®Œæˆ")

        except Exception as e:
            print(f"[ModelManager] æ¨¡å‹ä¸‹è½½å¤±è´¥: {e}")
            raise


class VoiceGenerator:
    """è¯­éŸ³ç”Ÿæˆå™¨ - ä¸“é—¨å¤„ç†è¯­éŸ³åˆæˆåŠŸèƒ½"""

    def __init__(self, path_manager):
        self.path_manager = path_manager
        self._melotts_models = {}  # ç¼“å­˜MeloTTSæ¨¡å‹å®ä¾‹

    def _get_or_create_melotts_model(self, language, device='cpu'):
        """è·å–æˆ–åˆ›å»ºMeloTTSæ¨¡å‹å®ä¾‹ï¼ˆå¸¦ç¼“å­˜ï¼‰"""
        cache_key = f"{language}_{device}"
        if cache_key not in self._melotts_models:
            print(f"[VoiceGenerator] åˆå§‹åŒ–MeloTTSæ¨¡å‹ (è¯­è¨€: {language}, è®¾å¤‡: {device})...")
            from melo.api import TTS
            self._melotts_models[cache_key] = TTS(language=language, device=device)
            print(f"[VoiceGenerator] MeloTTSæ¨¡å‹åˆå§‹åŒ–æˆåŠŸå¹¶ç¼“å­˜")
        return self._melotts_models[cache_key]


    def generate_with_melotts_tts(self, text, output_path, base_speaker_key="ZH" ,speed = 1.0):
        """å°è¯•ä½¿ç”¨MeloTTSç”Ÿæˆè¯­éŸ³"""
        # ä¿å­˜åŸå§‹ç¯å¢ƒå˜é‡
        import os
        original_mps_fallback = os.environ.get('PYTORCH_ENABLE_MPS_FALLBACK')
        original_cuda_devices = os.environ.get('CUDA_VISIBLE_DEVICES')

        try:
            print(f"[VoiceGenerator] å¼€å§‹ä½¿ç”¨MeloTTSç”Ÿæˆè¯­éŸ³...")
            print(f"[VoiceGenerator] è¾“å…¥æ–‡æœ¬: {text}")
            print(f"[VoiceGenerator] è¾“å‡ºè·¯å¾„: {output_path}")
            print(f"[VoiceGenerator] è¯´è¯äººkey: {base_speaker_key}")

            # # ä¸´æ—¶è®¾ç½®ç¯å¢ƒå˜é‡ï¼Œå¼ºåˆ¶ä½¿ç”¨CPUï¼Œé¿å…MPSé—®é¢˜
            # print(f"[VoiceGenerator] è®¾ç½®ç¯å¢ƒå˜é‡å¼ºåˆ¶ä½¿ç”¨CPU...")
            # os.environ['PYTORCH_ENABLE_MPS_FALLBACK'] = '0'
            # os.environ['CUDA_VISIBLE_DEVICES'] = ''
            # print(f"[VoiceGenerator] PYTORCH_ENABLE_MPS_FALLBACK: {os.environ.get('PYTORCH_ENABLE_MPS_FALLBACK')}")
            # print(f"[VoiceGenerator] CUDA_VISIBLE_DEVICES: {os.environ.get('CUDA_VISIBLE_DEVICES')}")

            device=DeviceUtils._get_optimal_device()

            print(f"[VoiceGenerator] é€‰æ‹©çš„è®¾å¤‡: {device}")

            print(f"[VoiceGenerator] æ­£åœ¨å¯¼å…¥MeloTTS...")
            from melo.api import TTS
            print(f"[VoiceGenerator] MeloTTSå¯¼å…¥æˆåŠŸ")

            # æ ¹æ®base_speaker_keyç¡®å®šè¯­è¨€
            language_mapping = {
                "EN_NEWEST": "EN", "EN": "EN",
                "ES": "ES", "FR": "FR",
                "ZH": "ZH", "JP": "JP", "KR": "KR"
            }

            language = language_mapping.get(base_speaker_key, "ZH")
            print(f"[VoiceGenerator] æ˜ å°„åè¯­è¨€: {language}")

            # ä½¿ç”¨ç¼“å­˜çš„æ¨¡å‹
            model = self._get_or_create_melotts_model(language, device=device)

            speaker_ids = model.hps.data.spk2id
            print(f"[VoiceGenerator] å¯ç”¨è¯´è¯äºº: {dict(speaker_ids)}")

            # é€‰æ‹©è¯´è¯äººID
            if base_speaker_key in speaker_ids:
                speaker_id = speaker_ids[base_speaker_key]
                print(f"[VoiceGenerator] ä½¿ç”¨æŒ‡å®šè¯´è¯äºº: {base_speaker_key} -> {speaker_id}")
            else:
                speaker_id = list(speaker_ids.values())[0]
                print(f"[VoiceGenerator] æœªæ‰¾åˆ°è¯´è¯äºº {base_speaker_key}ï¼Œä½¿ç”¨é»˜è®¤è¯´è¯äºº: {speaker_id}")

            # ç”Ÿæˆè¯­éŸ³
            print(f"[VoiceGenerator] å¼€å§‹ç”Ÿæˆè¯­éŸ³ (è¯­é€Ÿ: {speed})...")
            print(f"[VoiceGenerator] æ¨¡å‹å‚æ•°: è¯­è¨€={language}, è¯´è¯äººID={speaker_id}, è¾“å‡ºè·¯å¾„={output_path}")

            model.tts_to_file(
                text,
                speaker_id,
                output_path,
                speed=speed,
                sdp_ratio=0.2,        # éŸµå¾‹ç›¸ä¼¼åº¦
                noise_scale=0.6,      # éŸ³é¢‘å˜åŒ–åº¦
                noise_scale_w=0.8,    # éŸ³é¢‘è´¨é‡
                format='WAV'          # æ˜ç¡®æ ¼å¼

            )

            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦æˆåŠŸç”Ÿæˆ
            if os.path.exists(output_path):
                file_size = os.path.getsize(output_path)
                print(f"[VoiceGenerator] MeloTTSç”Ÿæˆè¯­éŸ³æˆåŠŸ: {output_path}")
                print(f"[VoiceGenerator] ç”Ÿæˆæ–‡ä»¶å¤§å°: {file_size} bytes")
                return True
            else:
                print(f"[VoiceGenerator] MeloTTSç”Ÿæˆå¤±è´¥: è¾“å‡ºæ–‡ä»¶ä¸å­˜åœ¨ {output_path}")
                return False

        except ImportError as ie:
            print(f"[VoiceGenerator] MeloTTSå¯¼å…¥é”™è¯¯: {ie}")
            print("[VoiceGenerator] MeloTTSæœªå®‰è£…")
            return False
        except Exception as e:
            print(f"[VoiceGenerator] MeloTTSç”Ÿæˆå¤±è´¥ - è¯¦ç»†é”™è¯¯: {type(e).__name__}: {e}")
            print(f"[VoiceGenerator] é”™è¯¯è¯¦æƒ…: {str(e)}")
            import traceback
            print(f"[VoiceGenerator] é”™è¯¯å †æ ˆ:")
            traceback.print_exc()
            return False
        finally:
            # æ¢å¤åŸå§‹ç¯å¢ƒå˜é‡
            if original_mps_fallback is not None:
                os.environ['PYTORCH_ENABLE_MPS_FALLBACK'] = original_mps_fallback
            else:
                os.environ.pop('PYTORCH_ENABLE_MPS_FALLBACK', None)

            if original_cuda_devices is not None:
                os.environ['CUDA_VISIBLE_DEVICES'] = original_cuda_devices
            else:
                os.environ.pop('CUDA_VISIBLE_DEVICES', None)

            print(f"[VoiceGenerator] å·²æ¢å¤åŸå§‹ç¯å¢ƒå˜é‡è®¾ç½®")


class OpenVoiceService:
    """
    OpenVoiceæœåŠ¡ä¸»ç±» - åè°ƒå„ä¸ªç»„ä»¶
    çº¿ç¨‹å®‰å…¨çš„æ‡’æ±‰å¼å•ä¾‹æ¨¡å¼
    """

    _instance = None
    _lock = threading.Lock()
    _initialized = False

    def __new__(cls):
        if cls._instance is None:
            cls._instance = super(OpenVoiceService, cls).__new__(cls)
        return cls._instance

    def __init__(self):
        if not OpenVoiceService._initialized:
            self._initialize_service()
            OpenVoiceService._initialized = True

    def _initialize_service(self):
        """å®é™…çš„æœåŠ¡åˆå§‹åŒ–é€»è¾‘"""
        print("[OpenVoice] ===============================================")
        print("[OpenVoice] åˆå§‹åŒ–OpenVoiceæœåŠ¡...")
        print("[OpenVoice] ===============================================")

        # åˆå§‹åŒ–ç»„ä»¶
        print("[OpenVoice] åˆå§‹åŒ–PathManager...")
        self.path_manager = PathManager()
        print(f"[OpenVoice] PathManageråˆå§‹åŒ–å®Œæˆï¼Œé¡¹ç›®æ ¹ç›®å½•: {self.path_manager.project_root}")

        print("[OpenVoice] åˆå§‹åŒ–ModelManager...")
        self.model_manager = ModelManager(self.path_manager)

        print("[OpenVoice] åˆå§‹åŒ–SpeakerFeatureManager...")
        self.feature_manager = SpeakerFeatureManager(self.path_manager)

        print("[OpenVoice] åˆå§‹åŒ–VoiceGenerator...")
        self.voice_generator = VoiceGenerator(self.path_manager)

        print("[OpenVoice] åˆå§‹åŒ–AudioProcessor...")
        self.audio_processor = AudioProcessor()

        # åˆå§‹åŒ–æ¨¡å‹
        print("[OpenVoice] å¼€å§‹åˆå§‹åŒ–æ¨¡å‹ç»„ä»¶...")
        # ç¡®ä¿tts_modelå±æ€§å­˜åœ¨ï¼ˆV2ç‰ˆæœ¬ä¸»è¦ä½¿ç”¨MeloTTSï¼‰
        self.tts_model = None
        self._initialize_components()

        print("[OpenVoice] ===============================================")
        print("[OpenVoice] OpenVoiceæœåŠ¡åˆå§‹åŒ–å®Œæˆ")
        print(f"[OpenVoice] æœåŠ¡ID: {id(self)}")
        print(f"[OpenVoice] éŸ³è‰²è½¬æ¢å™¨çŠ¶æ€: {'âœ… å·²åŠ è½½' if self.tone_converter else 'âŒ æœªåŠ è½½'}")
        print(f"[OpenVoice] å·²åŠ è½½è¯´è¯äººæ•°é‡: {len(self.feature_manager.speaker_features)}")
        print("==============================================")

    @classmethod
    def get_instance(cls):
        """
        è·å–OpenVoiceServiceå•ä¾‹å®ä¾‹

        Returns:
            OpenVoiceService: æœåŠ¡å®ä¾‹
        """
        if cls._instance is None:
            with cls._lock:
                if cls._instance is None:
                    cls._instance = cls()
        return cls._instance

    @classmethod
    def get(cls):
        """
        è·å–OpenVoiceServiceå•ä¾‹å®ä¾‹çš„ç®€åŒ–æ–¹æ³•

        Returns:
            OpenVoiceService: æœåŠ¡å®ä¾‹
        """
        return cls.get_instance()

    @classmethod
    def is_initialized(cls):
        """
        æ£€æŸ¥æœåŠ¡æ˜¯å¦å·²åˆå§‹åŒ–

        Returns:
            bool: æ˜¯å¦å·²åˆå§‹åŒ–
        """
        return cls._initialized

    @classmethod
    def reset_instance(cls):
        """
        é‡ç½®å•ä¾‹å®ä¾‹ï¼ˆä¸»è¦ç”¨äºæµ‹è¯•ï¼‰
        æ³¨æ„ï¼šè¿™ä¼šæ¸…é™¤å½“å‰å®ä¾‹ï¼Œä¸‹æ¬¡è°ƒç”¨get_instanceä¼šåˆ›å»ºæ–°å®ä¾‹
        """
        with cls._lock:
            if cls._instance is not None:
                # å¯ä»¥åœ¨è¿™é‡Œæ‰§è¡Œæ¸…ç†æ“ä½œ
                cls._instance = None
                cls._initialized = False

    def _initialize_components(self):
        """åˆå§‹åŒ–æ‰€æœ‰ç»„ä»¶"""
        print("[OpenVoice] å¼€å§‹ç»„ä»¶åˆå§‹åŒ–æµç¨‹...")
        if self.model_manager.initialize():
            self.tone_converter = self.model_manager.tone_converter
            print("[OpenVoice] âœ… ç»„ä»¶åˆå§‹åŒ–å®Œæˆ")
            print(f"[OpenVoice] è®¾å¤‡ç±»å‹: {self.model_manager.device}")
            print(f"[OpenVoice] éŸ³è‰²è½¬æ¢å™¨: {type(self.tone_converter).__name__}")
        else:
            print("[OpenVoice] âŒ æ¨¡å‹ç®¡ç†å™¨åˆå§‹åŒ–å¤±è´¥")
            self._fallback_to_default_state()

    def _fallback_to_default_state(self):
        """ç»„ä»¶åˆå§‹åŒ–å¤±è´¥æ—¶çš„é»˜è®¤çŠ¶æ€"""
        print("[OpenVoice] è¿›å…¥é»˜è®¤çŠ¶æ€ï¼ˆåŠŸèƒ½å—é™ï¼‰")
        self.tone_converter = None
        self.tts_model = None  # ç¡®ä¿å±æ€§å­˜åœ¨
        print("[OpenVoice] âš ï¸  ä½¿ç”¨é»˜è®¤çŠ¶æ€ï¼Œè¯­éŸ³åŠŸèƒ½ä¸å¯ç”¨")

    @property
    def device(self):
        """è·å–è®¾å¤‡ç±»å‹"""
        return self.model_manager.device

    @property
    def speaker_features(self):
        """è·å–è¯´è¯äººç‰¹å¾"""
        return self.feature_manager.speaker_features

    def list_available_speakers(self):
        """åˆ—å‡ºå¯ç”¨çš„è¯´è¯äºº"""
        return self.feature_manager.list_speakers()

    def extract_and_save_speaker_feature(self, speaker_id, reference_audio):
        """æå–å¹¶ä¿å­˜è¯´è¯äººç‰¹å¾ï¼ˆpublic : ä¾›å¤–éƒ¨å‡½æ•°è°ƒç”¨ï¼‰"""
        return self.feature_manager.extract_feature(speaker_id, reference_audio, self.tone_converter)

    def generate_speech(self, text, speaker_id=None):
        """ç”Ÿæˆè¯­éŸ³ - ç»Ÿä¸€æ¥å£ï¼ˆV2ç‰ˆæœ¬ï¼‰"""
        print("[OpenVoice] ===============================================")
        print("[OpenVoice] å¼€å§‹è¯­éŸ³ç”Ÿæˆæµç¨‹...")
        print(f"[OpenVoice] è¾“å…¥æ–‡æœ¬: '{text}'")
        print(f"[OpenVoice] è¯´è¯äººID: {speaker_id if speaker_id else 'None (ä½¿ç”¨åŸºç¡€TTS)'}")

        try:
            # è¾“å…¥éªŒè¯
            if not text or not text.strip():
                print("[OpenVoice]  è¾“å…¥æ–‡æœ¬ä¸ºç©º")
                return None

            text = text.strip()
            if len(text) > 1000:  # å‡è®¾æœ€å¤§æ–‡æœ¬é•¿åº¦
                print("[OpenVoice]  è¾“å…¥æ–‡æœ¬è¿‡é•¿ï¼Œæœ€å¤§æ”¯æŒ1000å­—ç¬¦")
                return None

            # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶å - ä½¿ç”¨PathManager
            timestamp = time.strftime("%Y%m%d_%H%M%S")
            output_path = self.path_manager.get_output_voice_path(timestamp)

            # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨ - ä½¿ç”¨PathManager
            self.path_manager.ensure_file_directory(output_path)

            print(f"[OpenVoice] è¾“å‡ºæ–‡ä»¶è·¯å¾„: {output_path}")

            if speaker_id and speaker_id in self.feature_manager.speaker_features:
                # ä½¿ç”¨è¯´è¯äººå…‹éš†ï¼ˆV2æ–¹å¼ï¼‰
                if not self.tone_converter:
                    print("[OpenVoice] âŒ è¯­éŸ³å…‹éš†éœ€è¦éŸ³è‰²è½¬æ¢å™¨ï¼Œä½†è½¬æ¢å™¨æœªåˆå§‹åŒ–")
                    return None

                print(f"[OpenVoice] ğŸ­ ä½¿ç”¨è¯´è¯äººå…‹éš†æ¨¡å¼: {speaker_id}")
                print(f"[OpenVoice] å¯ç”¨è¯´è¯äºº: {list(self.feature_manager.speaker_features.keys())}")
                return self._clone_voice_with_cached_feature(text, speaker_id, output_path)
            else:
                # ä½¿ç”¨åŸºç¡€TTSï¼ˆMeloTTSï¼‰
                print("[OpenVoice] ğŸ¤ ä½¿ç”¨åŸºç¡€TTSæ¨¡å¼ï¼ˆMeloTTSï¼‰")
                if speaker_id:
                    print(f"[OpenVoice] âš ï¸  è¯´è¯äºº {speaker_id} ä¸å­˜åœ¨ï¼Œåˆ‡æ¢åˆ°åŸºç¡€TTS")
                return self._generate_base_speech(text, output_path)

        except Exception as e:
            print(f"[OpenVoice] âŒ è¯­éŸ³ç”Ÿæˆå¼‚å¸¸: {type(e).__name__}: {e}")
            import traceback
            print(f"[OpenVoice] é”™è¯¯å †æ ˆ:")
            traceback.print_exc()
            return None

    def _clone_voice_with_cached_feature(self, text, speaker_id, output_path, base_speaker_key="ZH"):
        """ä½¿ç”¨ç¼“å­˜çš„è¯´è¯äººç‰¹å¾è¿›è¡Œè¯­éŸ³å…‹éš†"""
        temp_audio = None
        try:
            if not self.tone_converter:
                return None

            speaker_info = self.feature_manager.get_feature(speaker_id)
            target_se = speaker_info['se']
            # ç¡®ä¿ç›®æ ‡ç‰¹å¾ä¹Ÿåœ¨æ­£ç¡®çš„è®¾å¤‡ä¸Š
            target_se = target_se.to(self.model_manager.device)
            print(f"[OpenVoice]  ç›®æ ‡ç‰¹å¾è®¾å¤‡: {target_se.device}")

            # 1. å…ˆç”¨åŸºç¡€æ¨¡å‹ç”Ÿæˆè¯­éŸ³ï¼ˆä½¿ç”¨MeloTTSï¼‰
            temp_audio = self.path_manager.get_temp_voice_path(f"base_{speaker_id}")
            base_speaker_path = self._generate_base_speech(text, temp_audio, base_speaker_key)

            if not base_speaker_path:
                return None

            # 2. åŠ è½½åŸºç¡€è¯´è¯äººç‰¹å¾ - ä½¿ç”¨PathManager
            source_se_path = self.path_manager.get_root_begin_path("OpenVoice/checkpoints_v2/base_speakers/ses", f"{base_speaker_key.lower()}.pth")
            print(f"[OpenVoice]  æŸ¥æ‰¾åŸºç¡€è¯´è¯äººç‰¹å¾: {source_se_path}")
            print(f"[OpenVoice]  æ–‡ä»¶å­˜åœ¨: {os.path.exists(source_se_path)}")

            if os.path.exists(source_se_path):
                print(f"[OpenVoice]  å¼€å§‹åŠ è½½åŸºç¡€è¯´è¯äººç‰¹å¾...")
                source_se = torch.load(source_se_path, map_location=self.model_manager.device)
                print(f"[OpenVoice]  åŸºç¡€è¯´è¯äººç‰¹å¾åŠ è½½æˆåŠŸï¼Œå½¢çŠ¶: {source_se.shape}")
                print(f"[OpenVoice]  åŸºç¡€ç‰¹å¾è®¾å¤‡: {source_se.device}")
            else:
                print(f"[OpenVoice]  æœªæ‰¾åˆ°åŸºç¡€è¯´è¯äººç‰¹å¾: {source_se_path}")
                return None

            # 3. ä½¿ç”¨ç¼“å­˜çš„ç‰¹å¾è¿›è¡ŒéŸ³è‰²è½¬æ¢
            encode_message = "@MyShell"
            print(f"[OpenVoice]  å¼€å§‹éŸ³è‰²è½¬æ¢...")
            print(f"[OpenVoice]  è¾“å…¥éŸ³é¢‘: {temp_audio}")
            print(f"[OpenVoice]  è¾“å‡ºéŸ³é¢‘: {output_path}")
            print(f"[OpenVoice]  ç¼–ç æ¶ˆæ¯: {encode_message}")
            print(f"[OpenVoice]  ç›®æ ‡ç‰¹å¾å½¢çŠ¶: {target_se.shape}")
            self.tone_converter.convert(
                audio_src_path=temp_audio,
                src_se=source_se,
                tgt_se=target_se,
                output_path=output_path,
                message=encode_message
            )
            
            print(f"[OpenVoice]  éŸ³è‰²è½¬æ¢å®Œæˆ")
            
            print(f"[OpenVoice] ä½¿ç”¨V2æ¨¡å‹å’Œç¼“å­˜ç‰¹å¾ç”Ÿæˆè¯­éŸ³: {speaker_id}")
            return output_path

        except Exception as e:
            print(f"[OpenVoice] ä½¿ç”¨ç¼“å­˜ç‰¹å¾ç”Ÿæˆè¯­éŸ³å¤±è´¥: {e}")
            return None
        finally:
            # 4. ç¡®ä¿æ¸…ç†ä¸´æ—¶æ–‡ä»¶ï¼ˆå¼‚å¸¸å®‰å…¨ï¼‰
            if temp_audio and os.path.exists(temp_audio):
                try:
                    os.remove(temp_audio)
                    print(f"[OpenVoice] æ¸…ç†ä¸´æ—¶æ–‡ä»¶: {temp_audio}")
                except Exception as cleanup_error:
                    print(f"[OpenVoice] æ¸…ç†ä¸´æ—¶æ–‡ä»¶å¤±è´¥: {cleanup_error}")

    def _generate_base_speech(self, text, output_path, base_speaker_key="ZH"):
        """ç”ŸæˆåŸºç¡€è¯­éŸ³ï¼ˆæ”¯æŒMeloTTSï¼‰"""
        try:
            # å°è¯•ä½¿ç”¨MeloTTS
            if self.voice_generator.generate_with_melotts_tts(text, output_path, base_speaker_key):
                return output_path
            else:
                print("[OpenVoice] MeloTTSç”Ÿæˆå¤±è´¥")
                return None

        except Exception as e:
            print(f"[OpenVoice] åŸºç¡€è¯­éŸ³ç”Ÿæˆå¤±è´¥: {e}")
            return None

    # å…¼å®¹æ€§æ–¹æ³• - å§”æ‰˜ç»™ç›¸åº”çš„ç»„ä»¶ï¼Œç¡®ä¿ä¸äº§ç”Ÿé€’å½’è°ƒç”¨
    def initialize_model(self):
        """åˆå§‹åŒ–æ¨¡å‹ï¼ˆå…¼å®¹æ€§æ–¹æ³•ï¼‰"""
        return self._initialize_components()

    def load_speaker_features(self):
        """åŠ è½½å·²ä¿å­˜çš„è¯´è¯äººç‰¹å¾ï¼ˆå…¼å®¹æ€§æ–¹æ³•ï¼‰"""
        return self.feature_manager.speaker_features

    def save_speaker_feature(self, speaker_id, reference_audio, se_tensor):
        """ä¿å­˜è¯´è¯äººç‰¹å¾ï¼ˆå…¼å®¹æ€§æ–¹æ³•ï¼‰"""
        return self.feature_manager.save_feature(speaker_id, reference_audio, se_tensor)

    def clone_voice_with_cached_feature(self, text, speaker_id, output_path, base_speaker_key="ZH"):
        """ä½¿ç”¨ç¼“å­˜çš„è¯´è¯äººç‰¹å¾è¿›è¡Œè¯­éŸ³å…‹éš†ï¼ˆå…¼å®¹æ€§æ–¹æ³•ï¼‰"""
        return self._clone_voice_with_cached_feature(text, speaker_id, output_path, base_speaker_key)

    def generate_base_speech(self, text, output_path, base_speaker_key="ZH"):
        """ç”ŸæˆåŸºç¡€è¯­éŸ³ï¼ˆå…¼å®¹æ€§æ–¹æ³•ï¼‰"""
        return self._generate_base_speech(text, output_path, base_speaker_key)

    def try_melotts_tts(self, text, output_path, base_speaker_key="ZH"):
        """å°è¯•ä½¿ç”¨MeloTTSç”Ÿæˆè¯­éŸ³ï¼ˆå…¼å®¹æ€§æ–¹æ³•ï¼‰"""
        return self.voice_generator.generate_with_melotts_tts(text, output_path, base_speaker_key)

    def synthesize_speech(self, text, output_path, speaker="default", language="Chinese"):
        """å¿«é€Ÿè¯­éŸ³åˆæˆ - å…¼å®¹æ€§æ–¹æ³•"""
        try:
            # å°†languageå‚æ•°æ˜ å°„åˆ°MeloTTSçš„base_speaker_keyæ ¼å¼
            language_to_speaker_key = {
                "Chinese": "ZH",
                "English": "EN",
                "Spanish": "ES",
                "French": "FR",
                "Japanese": "JP",
                "Korean": "KR",
                "default": "ZH"
            }

            base_speaker_key = language_to_speaker_key.get(language, speaker.upper() if speaker.upper() in ["ZH", "EN", "ES", "FR", "JP", "KR"] else "ZH")

            print(f"[OpenVoice] synthesize_speech: language={language} -> base_speaker_key={base_speaker_key}, speaker={speaker}")

            # ä½¿ç”¨MeloTTSä½œä¸ºåŸºç¡€ç”Ÿæˆ
            return self._generate_base_speech(text, output_path, base_speaker_key)

        except Exception as e:
            print(f"[OpenVoice] è¯­éŸ³åˆæˆå¤±è´¥: {e}")
            return None

    def ensure_directories(self):
        """ç¡®ä¿å¿…è¦ç›®å½•å­˜åœ¨ï¼ˆå…¼å®¹æ€§æ–¹æ³•ï¼‰"""
        return self.model_manager._ensure_directories()

    def check_models_exist(self):
        """æ£€æŸ¥æ¨¡å‹æ–‡ä»¶æ˜¯å¦å­˜åœ¨ï¼ˆå…¼å®¹æ€§æ–¹æ³•ï¼‰"""
        return self.model_manager._check_models_exist()

    def download_openvoice_models(self):
        """ä¸‹è½½OpenVoice V2é¢„è®­ç»ƒæ¨¡å‹ï¼ˆå…¼å®¹æ€§æ–¹æ³•ï¼‰"""
        return self.model_manager._download_models()


class DeviceUtils:
    """è®¾å¤‡å·¥å…·ç±»ï¼Œæä¾›è®¾å¤‡ç›¸å…³çš„å®ç”¨æ–¹æ³•"""

    @staticmethod
    def _get_optimal_device():
        """æ™ºèƒ½è®¾å¤‡é€‰æ‹©"""
        if torch.cuda.is_available():
            # æ£€æŸ¥GPUå†…å­˜
            if torch.cuda.get_device_properties(0).total_memory > 4e9:  # 4GB+
                return "cuda"
        elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
            # Apple Siliconæ”¯æŒ
            return "mps"
        else:
            return "cpu"