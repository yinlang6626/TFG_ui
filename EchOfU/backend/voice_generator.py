import os
import time
import json
import subprocess
import torch
import librosa
import soundfile as sf
import numpy as np
from datetime import datetime
from openvoice.api import BaseSpeakerTTS, ToneColorConverter
from openvoice import se_extractor


class PathManager:
    """è·¯å¾„ç®¡ç†å™¨ï¼Œç»Ÿä¸€å¤„ç†æ‰€æœ‰è·¯å¾„ç›¸å…³é€»è¾‘"""

    def __init__(self):
        self.project_root = self._get_project_root()

    def _get_project_root(self):
        """è·å–é¡¹ç›®æ ¹ç›®å½•è·¯å¾„ - é€’å½’å‘ä¸ŠæŸ¥æ‰¾EchOfUç›®å½•"""
        def find_echofu_root(start_dir):
            current_dir = os.path.abspath(start_dir)

            # å¦‚æœå½“å‰ç›®å½•åæ˜¯EchOfUï¼Œæ£€æŸ¥æ˜¯å¦æœ‰OpenVoiceç›®å½•
            if os.path.basename(current_dir) == "EchOfU":
                if os.path.exists(os.path.join(current_dir, "OpenVoice")):
                    return current_dir

            # å¦‚æœå½“å‰ç›®å½•åŒ…å«EchOfUå­ç›®å½•ï¼Œä½¿ç”¨å®ƒ
            echofu_subdir = os.path.join(current_dir, "EchOfU")
            if os.path.exists(echofu_subdir) and os.path.exists(os.path.join(echofu_subdir, "OpenVoice")):
                return echofu_subdir

            # å¦‚æœå·²ç»åˆ°è¾¾æ ¹ç›®å½•è¿˜æ²¡æ‰¾åˆ°ï¼Œè¿”å›None
            parent_dir = os.path.dirname(current_dir)
            if parent_dir == current_dir:
                return None

            # é€’å½’å‘ä¸ŠæŸ¥æ‰¾
            return find_echofu_root(parent_dir)

        result = find_echofu_root(os.getcwd())
        if result is None:
            raise FileNotFoundError("æ— æ³•æ‰¾åˆ°EchOfUé¡¹ç›®æ ¹ç›®å½•")
        return result

    def get_model_path(self, *path_parts):
        """è·å–æ¨¡å‹ç›¸å…³è·¯å¾„"""
        return os.path.join(self.project_root, *path_parts)

    def get_openvoice_v2_path(self, *path_parts):
        """è·å–OpenVoice V2ç›¸å…³è·¯å¾„"""
        return self.get_model_path("OpenVoice/checkpoints_v2", *path_parts)

    def get_speaker_features_path(self):
        """è·å–è¯´è¯äººç‰¹å¾æ–‡ä»¶è·¯å¾„"""
        return os.path.join(self.project_root, "models/OpenVoice/speaker_features.json")

    def get_output_voice_path(self, timestamp):
        """ç”Ÿæˆè¾“å‡ºè¯­éŸ³æ–‡ä»¶è·¯å¾„"""
        return os.path.join(self.project_root, f"static/voices/generated_{timestamp}.wav")


class ModelDownloader:
    """æ¨¡å‹ä¸‹è½½å™¨ï¼Œå¤„ç†æ¨¡å‹æ–‡ä»¶çš„ä¸‹è½½å’Œè§£å‹"""

    @staticmethod
    def download_with_progress(url, output_path):
        """æ–‡ä»¶ä¸‹è½½è¿›åº¦æ˜¾ç¤º"""
        import requests

        try:
            response = requests.get(url, stream=True)
            response.raise_for_status()

            total_size = int(response.headers.get('content-length', 0))
            downloaded = 0

            with open(output_path, 'wb') as f:
                for chunk in response.iter_content(chunk_size=8192):
                    f.write(chunk)
                    downloaded += len(chunk)

                    if total_size > 0:
                        progress = (downloaded / total_size) * 100
                        print(f"\r[OpenVoice] ä¸‹è½½è¿›åº¦: {progress:.1f}%", end='', flush=True)

            print()  # æ¢è¡Œ

        except Exception as e:
            print(f"[OpenVoice] ä¸‹è½½å¤±è´¥: {e}")
            raise

    @staticmethod
    def extract_zip_file(zip_path, extract_dir):
        """è§£å‹zipæ–‡ä»¶"""
        import zipfile

        try:
            with zipfile.ZipFile(zip_path, 'r') as zip_ref:
                zip_ref.extractall(extract_dir)

            print(f"[OpenVoice] è§£å‹å®Œæˆ: {zip_path} -> {extract_dir}")

        except Exception as e:
            print(f"[OpenVoice] è§£å‹å¤±è´¥: {e}")
            raise


class AudioProcessor:
    """éŸ³é¢‘å¤„ç†å™¨ï¼Œå¤„ç†éŸ³é¢‘ç›¸å…³çš„æ“ä½œ"""

    def __init__(self):
        self.path_manager = PathManager()

    def extract_audio_from_video(self, video_path):
        """ä»è§†é¢‘ä¸­æå–éŸ³é¢‘"""
        try:
            # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨ - ä½¿ç”¨PathManager
            audio_dir = self.path_manager.get_model_path("static/audios")
            os.makedirs(audio_dir, exist_ok=True)

            # ç”ŸæˆéŸ³é¢‘æ–‡ä»¶å - ä½¿ç”¨PathManager
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            audio_output = os.path.join(audio_dir, f"extracted_{timestamp}.wav")

            # ä½¿ç”¨ffmpegæå–éŸ³é¢‘
            cmd = [
                "ffmpeg", "-i", video_path,
                "-vn",  # ç¦ç”¨è§†é¢‘
                "-acodec", "pcm_s16le",  # éŸ³é¢‘ç¼–ç 
                "-ar", "16000",  # é‡‡æ ·ç‡
                "-ac", "1",  # å•å£°é“
                "-y",  # è¦†ç›–è¾“å‡ºæ–‡ä»¶
                audio_output
            ]

            print(f"[backend.model_trainer] æå–éŸ³é¢‘å‘½ä»¤: {' '.join(cmd)}")

            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                timeout=60  # 1åˆ†é’Ÿè¶…æ—¶
            )

            if result.returncode == 0:
                print(f"[backend.model_trainer] éŸ³é¢‘æå–æˆåŠŸ: {audio_output}")
                return audio_output
            else:
                print(f"[backend.model_trainer] éŸ³é¢‘æå–å¤±è´¥: {result.stderr}")
                return None

    # [æ–°å¢åŠŸèƒ½] éŸ³é¢‘å˜è°ƒ (åŠ åˆ†é¡¹)
    def shift_pitch(self, input_path, n_steps):
        """
        å¯¹éŸ³é¢‘è¿›è¡Œå‡è°ƒæˆ–é™è°ƒ
        :param input_path: è¾“å…¥éŸ³é¢‘è·¯å¾„
        :param n_steps: åŠéŸ³æ•°ï¼Œæ­£æ•°å‡è°ƒï¼Œè´Ÿæ•°é™è°ƒ (ä¾‹å¦‚: 2, -1.5)
        :return: å¤„ç†åçš„éŸ³é¢‘è·¯å¾„
        """
        if not input_path or not os.path.exists(input_path):
            print("[AudioProcessor] è¾“å…¥éŸ³é¢‘ä¸å­˜åœ¨ï¼Œæ— æ³•å˜è°ƒ")
            return input_path

        if n_steps == 0:
            return input_path

        try:
            print(f"[AudioProcessor] æ­£åœ¨è¿›è¡Œå˜è°ƒå¤„ç†: {n_steps} steps...")
            # åŠ è½½éŸ³é¢‘ (sr=None ä¿æŒåŸå§‹é‡‡æ ·ç‡)
            y, sr = librosa.load(input_path, sr=None)
            
            # å˜è°ƒå¤„ç†
            y_shifted = librosa.effects.pitch_shift(y, sr=sr, n_steps=float(n_steps))
            
            # ç”Ÿæˆæ–°æ–‡ä»¶å
            dir_name = os.path.dirname(input_path)
            base_name = os.path.splitext(os.path.basename(input_path))[0]
            output_path = os.path.join(dir_name, f"{base_name}_pitch_{n_steps}.wav")
            
            # ä¿å­˜æ–‡ä»¶
            sf.write(output_path, y_shifted, sr)
            print(f"[AudioProcessor] å˜è°ƒå®Œæˆ: {output_path}")
            return output_path
        except Exception as e:
            print(f"[AudioProcessor] å˜è°ƒå¤±è´¥: {e}")
            # å¦‚æœå¤±è´¥ï¼Œè¿”å›åŸéŸ³é¢‘ï¼Œä¿è¯æµç¨‹ä¸ä¸­æ–­
            return input_path

        except subprocess.TimeoutExpired:
            print("[backend.model_trainer] éŸ³é¢‘æå–è¶…æ—¶")
            return None
        except Exception as e:
            print(f"[backend.model_trainer] éŸ³é¢‘æå–å¼‚å¸¸: {e}")
            return None


class SpeakerFeatureManager:
    """è¯´è¯äººç‰¹å¾ç®¡ç†å™¨ - ä¸“é—¨å¤„ç†è¯´è¯äººç‰¹å¾çš„åŠ è½½ã€ä¿å­˜å’Œç®¡ç†"""

    def __init__(self, path_manager):
        self.path_manager = path_manager
        self.speaker_features = {}
        self._load_all_features()

    def _load_all_features(self):
        """åŠ è½½æ‰€æœ‰å·²ä¿å­˜çš„è¯´è¯äººç‰¹å¾"""
        features_file = self.path_manager.get_speaker_features_path()
        if os.path.exists(features_file):
            try:
                with open(features_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)

                # åŠ è½½ç‰¹å¾å¼ é‡
                for speaker_id, info in data.items():
                    feature_path = info['feature_path']
                    if os.path.exists(feature_path):
                        self.speaker_features[speaker_id] = {
                            'se': torch.load(feature_path, map_location='cpu'),
                            'reference_audio': info['reference_audio'],
                            'created_time': info['created_time']
                        }

                print(f"[SpeakerFeatureManager] å·²åŠ è½½ {len(self.speaker_features)} ä¸ªè¯´è¯äººç‰¹å¾")
            except Exception as e:
                print(f"[SpeakerFeatureManager] åŠ è½½è¯´è¯äººç‰¹å¾å¤±è´¥: {e}")

    def save_feature(self, speaker_id, reference_audio, se_tensor):
        """ä¿å­˜è¯´è¯äººç‰¹å¾"""
        try:
            # ä¿å­˜ç‰¹å¾å¼ é‡ - ä½¿ç”¨PathManagerè·å–ç»å¯¹è·¯å¾„
            feature_path = self.path_manager.get_model_path("models/OpenVoice", f"{speaker_id}_se.pth")
            torch.save(se_tensor, feature_path)

            # ä¿å­˜å…ƒæ•°æ®
            metadata = {
                'feature_path': feature_path,
                'reference_audio': reference_audio,
                'created_time': time.strftime("%Y-%m-%d %H:%M:%S")
            }

            # æ›´æ–°ç‰¹å¾æ–‡ä»¶
            features_file = self.path_manager.get_speaker_features_path()
            all_features = {}
            if os.path.exists(features_file):
                with open(features_file, 'r', encoding='utf-8') as f:
                    all_features = json.load(f)

            all_features[speaker_id] = metadata

            with open(features_file, 'w', encoding='utf-8') as f:
                json.dump(all_features, f, indent=2, ensure_ascii=False)

            # æ›´æ–°å†…å­˜ä¸­çš„ç‰¹å¾
            self.speaker_features[speaker_id] = {
                'se': se_tensor,
                'reference_audio': reference_audio,
                'created_time': metadata['created_time']
            }

            print(f"[SpeakerFeatureManager] è¯´è¯äººç‰¹å¾å·²ä¿å­˜: {speaker_id}")

        except Exception as e:
            print(f"[SpeakerFeatureManager] ä¿å­˜è¯´è¯äººç‰¹å¾å¤±è´¥: {e}")

    def get_feature(self, speaker_id):
        """è·å–æŒ‡å®šè¯´è¯äººçš„ç‰¹å¾"""
        return self.speaker_features.get(speaker_id)

    def list_speakers(self):
        """åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„è¯´è¯äºº"""
        return list(self.speaker_features.keys())

    def extract_feature(self, speaker_id, reference_audio, tone_converter):
        """æå–è¯´è¯äººç‰¹å¾"""
        try:
            if not tone_converter:
                print(f"[SpeakerFeatureManager] è½¬æ¢å™¨æœªåˆå§‹åŒ–")
                return False

            print(f"[SpeakerFeatureManager] å¼€å§‹æå–è¯´è¯äººç‰¹å¾: {speaker_id}")

            # æå–è¯´è¯äººç‰¹å¾ - ä½¿ç”¨PathManagerè·å–processedç›®å½•çš„ç»å¯¹è·¯å¾„
            processed_dir = self.path_manager.get_model_path("processed")
            target_se_result = se_extractor.get_se(
                reference_audio,
                vc_model=tone_converter,
                target_dir=processed_dir
            )

            # get_seè¿”å›å…ƒç»„(se_tensor, audio_name) åªéœ€è¦å¼ é‡éƒ¨åˆ†
            if isinstance(target_se_result, tuple):
                target_se = target_se_result[0]
            else:
                target_se = target_se_result

            # ä¿å­˜ç‰¹å¾
            self.save_feature(speaker_id, reference_audio, target_se)

            print(f"[SpeakerFeatureManager] è¯´è¯äººç‰¹å¾æå–å®Œæˆ: {speaker_id}")
            return True

        except Exception as e:
            print(f"[SpeakerFeatureManager] è¯´è¯äººç‰¹å¾æå–å¤±è´¥: {e}")
            return False


class ModelManager:
    """æ¨¡å‹ç®¡ç†å™¨ - ä¸“é—¨å¤„ç†æ¨¡å‹çš„åˆå§‹åŒ–ã€ä¸‹è½½å’Œç®¡ç†"""

    def __init__(self, path_manager):
        self.path_manager = path_manager
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        self.tone_converter = None

    def initialize(self):
        """åˆå§‹åŒ–æ¨¡å‹"""
        try:
            # ç¡®ä¿ç›®å½•å­˜åœ¨
            self._ensure_directories()

            # æ£€æŸ¥æ¨¡å‹æ˜¯å¦å­˜åœ¨
            if not self._check_models_exist():
                print("[ModelManager] æ£€æµ‹åˆ°æ¨¡å‹æ–‡ä»¶ç¼ºå¤±ï¼Œå¼€å§‹è‡ªåŠ¨ä¸‹è½½...")
                self._download_models()

            # é…ç½®æ¨¡å‹è·¯å¾„ - ä½¿ç”¨PathManager
            config_path = self.path_manager.get_openvoice_v2_path("converter/config.json")
            base_ckpt = self.path_manager.get_openvoice_v2_path("converter/checkpoint.pth")

            # åŠ è½½éŸ³è‰²è½¬æ¢å™¨
            self.tone_converter = ToneColorConverter(config_path, device=self.device)
            self.tone_converter.load_ckpt(base_ckpt)

            print(f"[ModelManager] V2æ¨¡å‹åŠ è½½å®Œæˆï¼Œä½¿ç”¨è®¾å¤‡: {self.device}")
            return True

        except Exception as e:
            print(f"[ModelManager] æ¨¡å‹åˆå§‹åŒ–å¤±è´¥: {e}")
            return False

    def _ensure_directories(self):
        """ç¡®ä¿å¿…è¦ç›®å½•å­˜åœ¨"""
        dirs = [
            self.path_manager.get_openvoice_v2_path(),
            self.path_manager.get_model_path("OpenVoice/checkpoints/base_speakers"),
            self.path_manager.get_model_path("models/OpenVoice"),
            self.path_manager.get_model_path("static/voices"),
            self.path_manager.get_model_path("processed")
        ]
        for dir_path in dirs:
            os.makedirs(dir_path, exist_ok=True)

    def _check_models_exist(self):
        """æ£€æŸ¥æ¨¡å‹æ–‡ä»¶æ˜¯å¦å­˜åœ¨"""
        required_files = [
            self.path_manager.get_openvoice_v2_path("converter/config.json"),
            self.path_manager.get_openvoice_v2_path("converter/checkpoint.pth")
        ]

        missing = [f for f in required_files if not os.path.exists(f)]
        if missing:
            print(f"[ModelManager] ç¼ºå¤±æ¨¡å‹æ–‡ä»¶: {missing}")
            return False
        return True

    def _download_models(self):
        """ä¸‹è½½OpenVoice V2é¢„è®­ç»ƒæ¨¡å‹"""
        print("[ModelManager] ä¸‹è½½OpenVoice V2é¢„è®­ç»ƒæ¨¡å‹...")

        try:
            # V2æ¨¡å‹ä¸‹è½½åœ°å€
            zip_url = "https://myshell-public-repo-host.s3.amazonaws.com/openvoice/checkpoints_v2_0417.zip"

            # ä½¿ç”¨PathManagerè·å–è·¯å¾„
            project_root = self.path_manager.project_root
            zip_path = os.path.join(project_root, "OpenVoice/checkpoints_v2_0417.zip")
            extract_dir = os.path.join(project_root, "OpenVoice/")

            print(f"[ModelManager] ä¸‹è½½V2æ£€æŸ¥ç‚¹å‹ç¼©åŒ…...")
            ModelDownloader.download_with_progress(zip_url, zip_path)

            # è§£å‹å‹ç¼©åŒ…
            print(f"[ModelManager] è§£å‹æ£€æŸ¥ç‚¹æ–‡ä»¶...")
            ModelDownloader.extract_zip_file(zip_path, extract_dir)

            # æ¸…ç†å‹ç¼©åŒ…æ–‡ä»¶
            if os.path.exists(zip_path):
                os.remove(zip_path)
                print(f"[ModelManager] æ¸…ç†å‹ç¼©åŒ…æ–‡ä»¶: {zip_path}")

            print("[ModelManager] V2æ¨¡å‹ä¸‹è½½å’Œè§£å‹å®Œæˆ")

        except Exception as e:
            print(f"[ModelManager] æ¨¡å‹ä¸‹è½½å¤±è´¥: {e}")
            raise


class VoiceGenerator:
    """è¯­éŸ³ç”Ÿæˆå™¨ - ä¸“é—¨å¤„ç†è¯­éŸ³åˆæˆåŠŸèƒ½"""

    def __init__(self, path_manager):
        self.path_manager = path_manager
        self._melotts_models = {}  # ç¼“å­˜MeloTTSæ¨¡å‹å®ä¾‹

    def _get_or_create_melotts_model(self, language, device='cpu'):
        """è·å–æˆ–åˆ›å»ºMeloTTSæ¨¡å‹å®ä¾‹ï¼ˆå¸¦ç¼“å­˜ï¼‰"""
        cache_key = f"{language}_{device}"
        if cache_key not in self._melotts_models:
            print(f"[VoiceGenerator] åˆå§‹åŒ–MeloTTSæ¨¡å‹ (è¯­è¨€: {language}, è®¾å¤‡: {device})...")
            from melo.api import TTS
            self._melotts_models[cache_key] = TTS(language=language, device=device)
            print(f"[VoiceGenerator] MeloTTSæ¨¡å‹åˆå§‹åŒ–æˆåŠŸå¹¶ç¼“å­˜")
        return self._melotts_models[cache_key]

    def generate_with_melotts_tts(self, text, output_path, base_speaker_key="ZH"):
        """å°è¯•ä½¿ç”¨MeloTTSç”Ÿæˆè¯­éŸ³"""
        # ä¿å­˜åŸå§‹ç¯å¢ƒå˜é‡
        import os
        original_mps_fallback = os.environ.get('PYTORCH_ENABLE_MPS_FALLBACK')
        original_cuda_devices = os.environ.get('CUDA_VISIBLE_DEVICES')

        try:
            print(f"[VoiceGenerator] å¼€å§‹ä½¿ç”¨MeloTTSç”Ÿæˆè¯­éŸ³...")
            print(f"[VoiceGenerator] è¾“å…¥æ–‡æœ¬: {text}")
            print(f"[VoiceGenerator] è¾“å‡ºè·¯å¾„: {output_path}")
            print(f"[VoiceGenerator] è¯´è¯äººkey: {base_speaker_key}")

            # ä¸´æ—¶è®¾ç½®ç¯å¢ƒå˜é‡ï¼Œå¼ºåˆ¶ä½¿ç”¨CPUï¼Œé¿å…MPSé—®é¢˜
            print(f"[VoiceGenerator] è®¾ç½®ç¯å¢ƒå˜é‡å¼ºåˆ¶ä½¿ç”¨CPU...")
            os.environ['PYTORCH_ENABLE_MPS_FALLBACK'] = '0'
            os.environ['CUDA_VISIBLE_DEVICES'] = ''
            print(f"[VoiceGenerator] PYTORCH_ENABLE_MPS_FALLBACK: {os.environ.get('PYTORCH_ENABLE_MPS_FALLBACK')}")
            print(f"[VoiceGenerator] CUDA_VISIBLE_DEVICES: {os.environ.get('CUDA_VISIBLE_DEVICES')}")

            print(f"[VoiceGenerator] æ­£åœ¨å¯¼å…¥MeloTTS...")
            from melo.api import TTS
            print(f"[VoiceGenerator] MeloTTSå¯¼å…¥æˆåŠŸ")

            # æ ¹æ®base_speaker_keyç¡®å®šè¯­è¨€
            language_mapping = {
                "EN_NEWEST": "EN", "EN": "EN",
                "ES": "ES", "FR": "FR",
                "ZH": "ZH", "JP": "JP", "KR": "KR"
            }

            language = language_mapping.get(base_speaker_key, "EN")
            print(f"[VoiceGenerator] æ˜ å°„åè¯­è¨€: {language}")

            # ä½¿ç”¨ç¼“å­˜çš„æ¨¡å‹
            model = self._get_or_create_melotts_model(language, 'cpu')

            speaker_ids = model.hps.data.spk2id
            print(f"[VoiceGenerator] å¯ç”¨è¯´è¯äºº: {dict(speaker_ids)}")

            # é€‰æ‹©è¯´è¯äººID
            if base_speaker_key in speaker_ids:
                speaker_id = speaker_ids[base_speaker_key]
                print(f"[VoiceGenerator] ä½¿ç”¨æŒ‡å®šè¯´è¯äºº: {base_speaker_key} -> {speaker_id}")
            else:
                speaker_id = list(speaker_ids.values())[0]
                print(f"[VoiceGenerator] æœªæ‰¾åˆ°è¯´è¯äºº {base_speaker_key}ï¼Œä½¿ç”¨é»˜è®¤è¯´è¯äºº: {speaker_id}")

            # ç”Ÿæˆè¯­éŸ³
            speed = 1.0
            print(f"[VoiceGenerator] å¼€å§‹ç”Ÿæˆè¯­éŸ³ (è¯­é€Ÿ: {speed})...")
            print(f"[VoiceGenerator] æ¨¡å‹å‚æ•°: è¯­è¨€={language}, è¯´è¯äººID={speaker_id}, è¾“å‡ºè·¯å¾„={output_path}")

            model.tts_to_file(text, speaker_id, output_path, speed=speed)

            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦æˆåŠŸç”Ÿæˆ
            if os.path.exists(output_path):
                file_size = os.path.getsize(output_path)
                print(f"[VoiceGenerator] MeloTTSç”Ÿæˆè¯­éŸ³æˆåŠŸ: {output_path}")
                print(f"[VoiceGenerator] ç”Ÿæˆæ–‡ä»¶å¤§å°: {file_size} bytes")
                return True
            else:
                print(f"[VoiceGenerator] MeloTTSç”Ÿæˆå¤±è´¥: è¾“å‡ºæ–‡ä»¶ä¸å­˜åœ¨ {output_path}")
                return False

        except ImportError as ie:
            print(f"[VoiceGenerator] MeloTTSå¯¼å…¥é”™è¯¯: {ie}")
            print("[VoiceGenerator] MeloTTSæœªå®‰è£…")
            return False
        except Exception as e:
            print(f"[VoiceGenerator] MeloTTSç”Ÿæˆå¤±è´¥ - è¯¦ç»†é”™è¯¯: {type(e).__name__}: {e}")
            print(f"[VoiceGenerator] é”™è¯¯è¯¦æƒ…: {str(e)}")
            import traceback
            print(f"[VoiceGenerator] é”™è¯¯å †æ ˆ:")
            traceback.print_exc()
            return False
        finally:
            # æ¢å¤åŸå§‹ç¯å¢ƒå˜é‡
            if original_mps_fallback is not None:
                os.environ['PYTORCH_ENABLE_MPS_FALLBACK'] = original_mps_fallback
            else:
                os.environ.pop('PYTORCH_ENABLE_MPS_FALLBACK', None)

            if original_cuda_devices is not None:
                os.environ['CUDA_VISIBLE_DEVICES'] = original_cuda_devices
            else:
                os.environ.pop('CUDA_VISIBLE_DEVICES', None)

            print(f"[VoiceGenerator] å·²æ¢å¤åŸå§‹ç¯å¢ƒå˜é‡è®¾ç½®")


class OpenVoiceService:
    """OpenVoiceæœåŠ¡ä¸»ç±» - åè°ƒå„ä¸ªç»„ä»¶"""

    _instance = None
    _initialized = False

    def __new__(cls):
        if cls._instance is None:
            cls._instance = super(OpenVoiceService, cls).__new__(cls)
        return cls._instance

    def __init__(self):
        if not self._initialized:
            print("[OpenVoice] ===============================================")
            print("[OpenVoice] åˆå§‹åŒ–OpenVoiceæœåŠ¡...")
            print("[OpenVoice] ===============================================")

            # åˆå§‹åŒ–ç»„ä»¶
            print("[OpenVoice] åˆå§‹åŒ–PathManager...")
            self.path_manager = PathManager()
            print(f"[OpenVoice] PathManageråˆå§‹åŒ–å®Œæˆï¼Œé¡¹ç›®æ ¹ç›®å½•: {self.path_manager.project_root}")

            print("[OpenVoice] åˆå§‹åŒ–ModelManager...")
            self.model_manager = ModelManager(self.path_manager)

            print("[OpenVoice] åˆå§‹åŒ–SpeakerFeatureManager...")
            self.feature_manager = SpeakerFeatureManager(self.path_manager)

            print("[OpenVoice] åˆå§‹åŒ–VoiceGenerator...")
            self.voice_generator = VoiceGenerator(self.path_manager)

            print("[OpenVoice] åˆå§‹åŒ–AudioProcessor...")
            self.audio_processor = AudioProcessor()

            # åˆå§‹åŒ–æ¨¡å‹
            print("[OpenVoice] å¼€å§‹åˆå§‹åŒ–æ¨¡å‹ç»„ä»¶...")
            # ç¡®ä¿tts_modelå±æ€§å­˜åœ¨ï¼ˆV2ç‰ˆæœ¬ä¸»è¦ä½¿ç”¨MeloTTSï¼‰
            self.tts_model = None
            self._initialize_components()
            OpenVoiceService._initialized = True

            print("[OpenVoice] ===============================================")
            print("[OpenVoice] OpenVoiceæœåŠ¡åˆå§‹åŒ–å®Œæˆ")
            print(f"[OpenVoice] æœåŠ¡ID: {id(self)}")
            print(f"[OpenVoice] éŸ³è‰²è½¬æ¢å™¨çŠ¶æ€: {'âœ… å·²åŠ è½½' if self.tone_converter else 'âŒ æœªåŠ è½½'}")
            print(f"[OpenVoice] å·²åŠ è½½è¯´è¯äººæ•°é‡: {len(self.feature_manager.speaker_features)}")
            print("==============================================")

    def _initialize_components(self):
        """åˆå§‹åŒ–æ‰€æœ‰ç»„ä»¶"""
        print("[OpenVoice] å¼€å§‹ç»„ä»¶åˆå§‹åŒ–æµç¨‹...")
        if self.model_manager.initialize():
            self.tone_converter = self.model_manager.tone_converter
            print("[OpenVoice] âœ… ç»„ä»¶åˆå§‹åŒ–å®Œæˆ")
            print(f"[OpenVoice] è®¾å¤‡ç±»å‹: {self.model_manager.device}")
            print(f"[OpenVoice] éŸ³è‰²è½¬æ¢å™¨: {type(self.tone_converter).__name__}")
        else:
            print("[OpenVoice] âŒ æ¨¡å‹ç®¡ç†å™¨åˆå§‹åŒ–å¤±è´¥")
            self._fallback_to_default_state()

    def _fallback_to_default_state(self):
        """ç»„ä»¶åˆå§‹åŒ–å¤±è´¥æ—¶çš„é»˜è®¤çŠ¶æ€"""
        print("[OpenVoice] è¿›å…¥é»˜è®¤çŠ¶æ€ï¼ˆåŠŸèƒ½å—é™ï¼‰")
        self.tone_converter = None
        self.tts_model = None  # ç¡®ä¿å±æ€§å­˜åœ¨
        print("[OpenVoice] âš ï¸  ä½¿ç”¨é»˜è®¤çŠ¶æ€ï¼Œè¯­éŸ³åŠŸèƒ½ä¸å¯ç”¨")

    @property
    def device(self):
        """è·å–è®¾å¤‡ç±»å‹"""
        return self.model_manager.device

    @property
    def speaker_features(self):
        """è·å–è¯´è¯äººç‰¹å¾"""
        return self.feature_manager.speaker_features

    def list_available_speakers(self):
        """åˆ—å‡ºå¯ç”¨çš„è¯´è¯äºº"""
        return self.feature_manager.list_speakers()

    def extract_and_save_speaker_feature(self, speaker_id, reference_audio):
        """æå–å¹¶ä¿å­˜è¯´è¯äººç‰¹å¾ï¼ˆpublic : ä¾›å¤–éƒ¨å‡½æ•°è°ƒç”¨ï¼‰"""
        return self.feature_manager.extract_feature(speaker_id, reference_audio, self.tone_converter)

    def generate_speech(self, text, speaker_id=None):
        """ç”Ÿæˆè¯­éŸ³ - ç»Ÿä¸€æ¥å£ï¼ˆV2ç‰ˆæœ¬ï¼‰"""
        print("[OpenVoice] ===============================================")
        print("[OpenVoice] å¼€å§‹è¯­éŸ³ç”Ÿæˆæµç¨‹...")
        print(f"[OpenVoice] è¾“å…¥æ–‡æœ¬: '{text}'")
        print(f"[OpenVoice] è¯´è¯äººID: {speaker_id if speaker_id else 'None (ä½¿ç”¨åŸºç¡€TTS)'}")

        try:
            # è¾“å…¥éªŒè¯
            if not text or not text.strip():
                print("[OpenVoice]  è¾“å…¥æ–‡æœ¬ä¸ºç©º")
                return None

            text = text.strip()
            if len(text) > 1000:  # å‡è®¾æœ€å¤§æ–‡æœ¬é•¿åº¦
                print("[OpenVoice]  è¾“å…¥æ–‡æœ¬è¿‡é•¿ï¼Œæœ€å¤§æ”¯æŒ1000å­—ç¬¦")
                return None

            # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶å - ä½¿ç”¨PathManager
            timestamp = time.strftime("%Y%m%d_%H%M%S")
            output_path = self.path_manager.get_output_voice_path(timestamp)

            # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
            output_dir = os.path.dirname(output_path)
            os.makedirs(output_dir, exist_ok=True)

            print(f"[OpenVoice] è¾“å‡ºæ–‡ä»¶è·¯å¾„: {output_path}")

            if speaker_id and speaker_id in self.feature_manager.speaker_features:
                # ä½¿ç”¨è¯´è¯äººå…‹éš†ï¼ˆV2æ–¹å¼ï¼‰
                if not self.tone_converter:
                    print("[OpenVoice] âŒ è¯­éŸ³å…‹éš†éœ€è¦éŸ³è‰²è½¬æ¢å™¨ï¼Œä½†è½¬æ¢å™¨æœªåˆå§‹åŒ–")
                    return None

                print(f"[OpenVoice] ğŸ­ ä½¿ç”¨è¯´è¯äººå…‹éš†æ¨¡å¼: {speaker_id}")
                print(f"[OpenVoice] å¯ç”¨è¯´è¯äºº: {list(self.feature_manager.speaker_features.keys())}")
                return self._clone_voice_with_cached_feature(text, speaker_id, output_path)
            else:
                # ä½¿ç”¨åŸºç¡€TTSï¼ˆMeloTTSï¼‰
                print("[OpenVoice] ğŸ¤ ä½¿ç”¨åŸºç¡€TTSæ¨¡å¼ï¼ˆMeloTTSï¼‰")
                if speaker_id:
                    print(f"[OpenVoice] âš ï¸  è¯´è¯äºº {speaker_id} ä¸å­˜åœ¨ï¼Œåˆ‡æ¢åˆ°åŸºç¡€TTS")
                return self._generate_base_speech(text, output_path)

        except Exception as e:
            print(f"[OpenVoice] âŒ è¯­éŸ³ç”Ÿæˆå¼‚å¸¸: {type(e).__name__}: {e}")
            import traceback
            print(f"[OpenVoice] é”™è¯¯å †æ ˆ:")
            traceback.print_exc()
            return None

    def _clone_voice_with_cached_feature(self, text, speaker_id, output_path, base_speaker_key="ZH"):
        """ä½¿ç”¨ç¼“å­˜çš„è¯´è¯äººç‰¹å¾è¿›è¡Œè¯­éŸ³å…‹éš†"""
        temp_audio = None
        try:
            if not self.tone_converter:
                return None

            speaker_info = self.feature_manager.get_feature(speaker_id)
            target_se = speaker_info['se']

            # 1. å…ˆç”¨åŸºç¡€æ¨¡å‹ç”Ÿæˆè¯­éŸ³ï¼ˆä½¿ç”¨MeloTTSï¼‰
            temp_audio = os.path.join(self.path_manager.project_root, f"temp_base_{speaker_id}_{int(time.time())}.wav")
            base_speaker_path = self._generate_base_speech(text, temp_audio, base_speaker_key)

            if not base_speaker_path:
                return None

            # 2. åŠ è½½åŸºç¡€è¯´è¯äººç‰¹å¾ - ä½¿ç”¨PathManager
            source_se_path = self.path_manager.get_model_path("OpenVoice/checkpoints_v2/base_speakers/ses", f"{base_speaker_key.lower()}.pth")
            if os.path.exists(source_se_path):
                source_se = torch.load(source_se_path, map_location=self.model_manager.device)
            else:
                print(f"[OpenVoice] æœªæ‰¾åˆ°åŸºç¡€è¯´è¯äººç‰¹å¾: {source_se_path}")
                return None

            # 3. ä½¿ç”¨ç¼“å­˜çš„ç‰¹å¾è¿›è¡ŒéŸ³è‰²è½¬æ¢
            encode_message = "@MyShell"
            self.tone_converter.convert(
                audio_src_path=temp_audio,
                src_se=source_se,
                tgt_se=target_se,
                output_path=output_path,
                message=encode_message
            )

            print(f"[OpenVoice] ä½¿ç”¨V2æ¨¡å‹å’Œç¼“å­˜ç‰¹å¾ç”Ÿæˆè¯­éŸ³: {speaker_id}")
            return output_path

        except Exception as e:
            print(f"[OpenVoice] ä½¿ç”¨ç¼“å­˜ç‰¹å¾ç”Ÿæˆè¯­éŸ³å¤±è´¥: {e}")
            return None
        finally:
            # 4. ç¡®ä¿æ¸…ç†ä¸´æ—¶æ–‡ä»¶ï¼ˆå¼‚å¸¸å®‰å…¨ï¼‰
            if temp_audio and os.path.exists(temp_audio):
                try:
                    os.remove(temp_audio)
                    print(f"[OpenVoice] æ¸…ç†ä¸´æ—¶æ–‡ä»¶: {temp_audio}")
                except Exception as cleanup_error:
                    print(f"[OpenVoice] æ¸…ç†ä¸´æ—¶æ–‡ä»¶å¤±è´¥: {cleanup_error}")

    def _generate_base_speech(self, text, output_path, base_speaker_key="ZH"):
        """ç”ŸæˆåŸºç¡€è¯­éŸ³ï¼ˆæ”¯æŒMeloTTSï¼‰"""
        try:
            # å°è¯•ä½¿ç”¨MeloTTS
            if self.voice_generator.generate_with_melotts_tts(text, output_path, base_speaker_key):
                return output_path
            else:
                print("[OpenVoice] MeloTTSç”Ÿæˆå¤±è´¥")
                return None

        except Exception as e:
            print(f"[OpenVoice] åŸºç¡€è¯­éŸ³ç”Ÿæˆå¤±è´¥: {e}")
            return None

    # å…¼å®¹æ€§æ–¹æ³• - å§”æ‰˜ç»™ç›¸åº”çš„ç»„ä»¶ï¼Œç¡®ä¿ä¸äº§ç”Ÿé€’å½’è°ƒç”¨
    def initialize_model(self):
        """åˆå§‹åŒ–æ¨¡å‹ï¼ˆå…¼å®¹æ€§æ–¹æ³•ï¼‰"""
        return self._initialize_components()

    def load_speaker_features(self):
        """åŠ è½½å·²ä¿å­˜çš„è¯´è¯äººç‰¹å¾ï¼ˆå…¼å®¹æ€§æ–¹æ³•ï¼‰"""
        return self.feature_manager.speaker_features

    def save_speaker_feature(self, speaker_id, reference_audio, se_tensor):
        """ä¿å­˜è¯´è¯äººç‰¹å¾ï¼ˆå…¼å®¹æ€§æ–¹æ³•ï¼‰"""
        return self.feature_manager.save_feature(speaker_id, reference_audio, se_tensor)

    def clone_voice_with_cached_feature(self, text, speaker_id, output_path, base_speaker_key="ZH"):
        """ä½¿ç”¨ç¼“å­˜çš„è¯´è¯äººç‰¹å¾è¿›è¡Œè¯­éŸ³å…‹éš†ï¼ˆå…¼å®¹æ€§æ–¹æ³•ï¼‰"""
        return self._clone_voice_with_cached_feature(text, speaker_id, output_path, base_speaker_key)

    def generate_base_speech(self, text, output_path, base_speaker_key="ZH"):
        """ç”ŸæˆåŸºç¡€è¯­éŸ³ï¼ˆå…¼å®¹æ€§æ–¹æ³•ï¼‰"""
        return self._generate_base_speech(text, output_path, base_speaker_key)

    def try_melotts_tts(self, text, output_path, base_speaker_key="ZH"):
        """å°è¯•ä½¿ç”¨MeloTTSç”Ÿæˆè¯­éŸ³ï¼ˆå…¼å®¹æ€§æ–¹æ³•ï¼‰"""
        return self.voice_generator.generate_with_melotts_tts(text, output_path, base_speaker_key)

    def synthesize_speech(self, text, output_path, speaker="default", language="Chinese"):
        """å¿«é€Ÿè¯­éŸ³åˆæˆ - å…¼å®¹æ€§æ–¹æ³•"""
        try:
            # å°†languageå‚æ•°æ˜ å°„åˆ°MeloTTSçš„base_speaker_keyæ ¼å¼
            language_to_speaker_key = {
                "Chinese": "ZH",
                "English": "EN",
                "Spanish": "ES",
                "French": "FR",
                "Japanese": "JP",
                "Korean": "KR",
                "default": "ZH"
            }

            base_speaker_key = language_to_speaker_key.get(language, speaker.upper() if speaker.upper() in ["ZH", "EN", "ES", "FR", "JP", "KR"] else "ZH")

            print(f"[OpenVoice] synthesize_speech: language={language} -> base_speaker_key={base_speaker_key}, speaker={speaker}")

            # ä½¿ç”¨MeloTTSä½œä¸ºåŸºç¡€ç”Ÿæˆ
            return self._generate_base_speech(text, output_path, base_speaker_key)

        except Exception as e:
            print(f"[OpenVoice] è¯­éŸ³åˆæˆå¤±è´¥: {e}")
            return None

    def ensure_directories(self):
        """ç¡®ä¿å¿…è¦ç›®å½•å­˜åœ¨ï¼ˆå…¼å®¹æ€§æ–¹æ³•ï¼‰"""
        return self.model_manager._ensure_directories()

    def check_models_exist(self):
        """æ£€æŸ¥æ¨¡å‹æ–‡ä»¶æ˜¯å¦å­˜åœ¨ï¼ˆå…¼å®¹æ€§æ–¹æ³•ï¼‰"""
        return self.model_manager._check_models_exist()

    def download_openvoice_models(self):
        """ä¸‹è½½OpenVoice V2é¢„è®­ç»ƒæ¨¡å‹ï¼ˆå…¼å®¹æ€§æ–¹æ³•ï¼‰"""
        return self.model_manager._download_models()
